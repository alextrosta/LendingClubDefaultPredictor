{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Author: Alex Trostanovsky, 31-08-2018\n",
    "#\n",
    "# This notebook contains the Exploratory Data Analysis I've conducted on Lending Club data\n",
    "# Using third party data sources from:\n",
    "# -  United States Department of Labour\n",
    "# -  International Health Organization\n",
    "#\n",
    "# This notebook:\n",
    "#\n",
    "# 1) categorizes 'emp_title' data into discrete categories outlined by the International Labour Organization's (ILO) \n",
    "#    International Standard Classification of Occupations (ISCO)\n",
    "#\n",
    "# 3) splits into training/testing datasets, and trains a LightGBM classifier to categorize loan candidates who're are likely\n",
    "#    to default (e.g. either 'Charged Off', 'Default', '30-120 Days Late)\n",
    "#\n",
    "# 4) produces cross-validation (AUCROC) metric result on the testing data-set with the trained model\n",
    "#\n",
    "# 5) generates a '_feature_importances' table for the trained model \n",
    "\n",
    "from contextlib               import contextmanager\n",
    "from lightgbm                 import LGBMClassifier\n",
    "from lightgbm                 import LGBMRegressor\n",
    "from sklearn.metrics          import roc_auc_score, roc_curve\n",
    "from sklearn.metrics          import mean_squared_error\n",
    "from sklearn.model_selection  import KFold, StratifiedKFold\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from math                     import sqrt\n",
    "from tqdm                     import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gc\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "invalidChars = set(string.punctuation)\n",
    "\n",
    "# remove all non-alphabetical characters from string\n",
    "\n",
    "def sanitize(job):\n",
    "    for char in invalidChars:\n",
    "        if char in job:\n",
    "            job = job.replace(char, ' ')\n",
    "    \n",
    "    if len(job) <= 3:\n",
    "        arr = job.split(' ')\n",
    "        arr = filter(None, arr)\n",
    "        job = ''.join(arr)\n",
    "    \n",
    "    return job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# translate all acronyms from a self-developed dict to their explicit strings\n",
    "\n",
    "def explicate(occ):\n",
    "  \n",
    "    array = occ.split(' ')     \n",
    "    array = [x.replace(x, acronyms[x]) if x in acronyms else x for x in array]\n",
    "    return ' '.join(array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in globally declared dicts necessary for translation and lookups performed in data preprocessing\n",
    "\n",
    "import ast\n",
    "\n",
    "# widely used acronyms in LC data \n",
    "\n",
    "with open('../data/lc/acronyms.txt') as infile: \n",
    "    acronyms = ast.literal_eval(infile.read().replace('acronyms = ', ''))\n",
    "\n",
    "# top 200 most common 'emp_title' strings in LC data with their corresponding 2 digit isco_08 code\n",
    "\n",
    "with open('../data/lc/top200occs_lc.txt') as infile: \n",
    "    sub_major_dict = ast.literal_eval(infile.read())\n",
    "\n",
    "# all 2-digit sub-major isco_08 codes with their corresponding titles\n",
    "\n",
    "with open('../data/third_party/sub_major_titles.txt') as infile: \n",
    "    sub_major_title_dict = ast.literal_eval(infile.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checks for common columns in the train/test df and returns only those which are common to both\n",
    "\n",
    "def filter_common_columns(train_df, test_df):\n",
    "    \n",
    "    array = []\n",
    "    \n",
    "    for element in test_df.columns.tolist():\n",
    "        if element not in train_df.columns.tolist():\n",
    "            array.append(element)\n",
    "            \n",
    "    for element in train_df.columns.tolist():\n",
    "        if element not in test_df.columns.tolist():\n",
    "            array.append(element)\n",
    "            \n",
    "    for col in array: \n",
    "        if col in test_df.columns.tolist():\n",
    "            test_df.drop(columns = [col], inplace = True)\n",
    "        elif col in train_df.columns.tolist():\n",
    "            train_df.drop(columns = [col], inplace = True)\n",
    "    \n",
    "    return train_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display/plot feature importance\n",
    "def display_importances(feature_importance_df_):\n",
    "    cols = feature_importance_df_[[\"feature\", \"importance\"]].groupby(\"feature\").mean().sort_values(by=\"importance\", ascending=False)[:40].index\n",
    "    best_features = feature_importance_df_.loc[feature_importance_df_.feature.isin(cols)]\n",
    "    plt.figure(figsize=(8, 10))\n",
    "    sns.barplot(x=\"importance\", y=\"feature\", data=best_features.sort_values(by=\"importance\", ascending=False))\n",
    "    plt.title('LightGBM Features (avg over folds)')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('lgbm_importances01.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading LoanStats3b_securev1.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2728: DtypeWarning: Columns (0,49,129,130,131,134,135,136,139) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading LoanStats3c_securev1.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2728: DtypeWarning: Columns (0,19) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading LoanStats3d_securev1.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2728: DtypeWarning: Columns (0,19,59) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading LoanStats_securev1_2016Q1.csv\n",
      "reading LoanStats_securev1_2016Q2.csv\n",
      "reading LoanStats_securev1_2016Q3.csv\n",
      "reading LoanStats_securev1_2016Q4.csv\n",
      "reading LoanStats_securev1_2017Q1.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2728: DtypeWarning: Columns (0,118) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading LoanStats_securev1_2017Q2.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2728: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading LoanStats_securev1_2017Q3.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2728: DtypeWarning: Columns (0,129,130,131,134,135,136,139) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading LoanStats_securev1_2017Q4.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2728: DtypeWarning: Columns (0,129,130,131,134,135,136,139,145,146,147) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading LoanStats_securev1_2018Q1.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2728: DtypeWarning: Columns (0,145,146,147) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading LoanStats_securev1_2018Q2.csv\n"
     ]
    }
   ],
   "source": [
    "# read in all files other than 2007-2011 \n",
    "#(07-11 df contains employee titles which describe the actual organization name (KFC)\n",
    "# as opposed to the occupation type (deep fryer))\n",
    "#\n",
    "# *** would be interesting to conduct a similar categorization on 2007-2011 dataset based on organization names and types\n",
    "\n",
    "import os\n",
    "\n",
    "files = os.listdir('../data/lc/secure')\n",
    "\n",
    "#files = os.listdir('../data/YOUR_LC_DATA_DIRECTORY')\n",
    "\n",
    "df = pd.DataFrame()\n",
    "for name in files:\n",
    "    if name != 'LoanStats3a_securev1.csv':\n",
    "        print('reading ' + name)\n",
    "        #skip first\n",
    "        temp = pd.read_csv('../data/lc/secure/' + name, skiprows = [0])\n",
    "        df = df.append(temp, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Current               902986\n",
       "Fully Paid            788945\n",
       "Charged Off           202993\n",
       "Issued                 27596\n",
       "Late (31-120 days)     20178\n",
       "In Grace Period        11372\n",
       "Late (16-30 days)       6179\n",
       "Default                 1278\n",
       "Name: loan_status, dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['loan_status'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "translating employee titles\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1831568/1831568 [00:01<00:00, 1027815.21it/s]\n",
      "100%|██████████| 1831568/1831568 [00:04<00:00, 415887.30it/s]\n",
      "100%|██████████| 1831568/1831568 [00:03<00:00, 577778.00it/s]\n"
     ]
    }
   ],
   "source": [
    "print('translating employee titles')\n",
    "    \n",
    "df = categorize_emp_titles(df)\n",
    "\n",
    "# translate (categorize) 'emp_title' column\n",
    "df['sub_mjr_grp_isco_08_code']  = df['job'].dropna().replace(sub_major_dict)\n",
    "df['sub_mjr_grp_isco_08_title'] = df['sub_mjr_grp_isco_08_code'].dropna().replace(sub_major_title_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get rid of all rows which were not categorized\n",
    "\n",
    "df['isnumeric'] = df['sub_mjr_grp_isco_08_code'].dropna().str.isnumeric()\n",
    "df = df[df['isnumeric'] == True]\n",
    "df.reset_index(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code all 'Default', 'Charged off', and 'Late (30-120)' as 'target' == 1 (i.e. defaulted on loan)\n",
    "# all other statuses as 0\n",
    "\n",
    "df['status'] = df['loan_status'].apply(lambda x: x in ['Charged Off', 'Default', 'Late (31-120 days)'])\n",
    "df['target'] = df.status.astype(int)\n",
    "\n",
    "# remove all unneeded columns\n",
    "\n",
    "droplist = ['status', 'isnumeric', 'sub_mjr_grp_isco_08_code', 'job', 'emp_title', 'index', 'loan_status']\n",
    "df.drop(columns = droplist, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export df prior to preprocessing of 3rd party data sources\n",
    "\n",
    "df.to_csv('../data/exports/coded_emp_target.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
